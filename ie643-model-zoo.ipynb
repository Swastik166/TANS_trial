{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/Swastik166/TANS_trial.git\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.insert(0, './TANS_trial')\n!pip install config","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%bash\ncd TANS_trial\npython3 main.py --gpu 0 --mode train --batch-size 140 --n-epochs 10000 --base-path path/for/storing/outcomes/ --data-path path/to/processed/dataset/is/stored/ --model-zoo path/to/model_zoo.pt --seed 777 ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport random\nimport torchvision.models as models\n\"\"\"add utils from misc and use the finctions available in for better error handling\"\"\"\n\nclass ModelZoo:\n    def __init__(self, datasets, seed):\n        self.seed = seed\n        self.datasets = ['dataset1']\n        self.models = {}\n        self.train_instances = {}\n        self.noise = torch.load('/path/to/noise.pt')\n        torch.cuda.manual_seed(self.seed)\n        torch.manual_seed(self.seed)\n        np.random.seed(self.seed)\n        random.seed(self.seed)\n\n    def init_loaders(self):\n        # Get loaders for train, test, and validation data\n        self.tr_dataset, self.tr_loader = get_loader(dataset, 'train')\n        self.te_dataset, self.te_loader = get_loader(dataset, 'test')\n        self.val_dataset, self.val_loader = get_loader(dataset, 'validation')\n        self.nclass = self.tr_dataset.get_nclss()\n        \n    def create_zoo(self):\n        model_zoo_dict = {}\n\n        for dataset in self.datasets:\n            # Initializing loaders for the dataset\n            self.init_loaders(dataset)\n\n            acc_list = []\n            n_params_list = []\n            topol_list = []\n\n            for _ in range(10):\n                # Get neural network model and topology information\n                self.topol, self.net = self.get_net(ncalss)\n\n                # Training the model and obtaining accuracy\n                self.lss = torch.nn.CrossEntropyLoss()\n                self.optim = torch.optim.SGD(self.net.parameters(), lr=1e-2, momentum=0.9, weight_decay=4e-5)\n                self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optim , float(self.args.n_eps_finetuning))\n                lss, acc = self.train()\n                \n                acc = self.train(net, dataset, data_loader)  # Assuming train method returns accuracy\n                acc_list.append(acc)\n\n                # Calculating number of parameters\n                n_params = self.n_param(net)\n                n_params_list.append(n_params)\n\n                topol_list.append(topol)\n                \n                del self.net\n                del self.optim\n                del self.lss\n                \n\n            # Save values for this dataset in the model_zoo_dict\n            model_zoo_dict[dataset] = {\n                'acc': acc_list,\n                'n_params': n_params_list,\n                'topol': topol_list\n            }\n\n        torch.save(model_zoo_dict, 'model_zoo.pt')\n\n    def get_net(self,nclss):\n        super_net_name = \"ofa_supernet_mbv3_w10\"\n\n        # Load the super network from the 'mit-han-lab/once-for-all' repository\n        super_net = torch.hub.load('mit-han-lab/once-for-all', super_net_name, pretrained=True).eval()\n\n        # Sample an active subnet configuration from the super network\n        sampled_config = super_net.sample_active_subnet()\n\n        # Extract topology information from the sampled configuration\n        pre_topol = list(sampled_config.values())\n        topol = []\n\n        for i in pre_topol:\n            for j in i:\n                topol.append(j)\n\n        # Split the topology into kernel sizes, expansion ratios, and depths\n        ks = topol[:20] \n        e = topol[20:40]\n        d = topol[40:]\n\n        # Set the active subnet in the super network using the sampled topology\n        super_net.set_active_subnet(ks=ks, e=e, d=d)\n        active_subnet = super_net.get_active_subnet(preserve_weight=True)\n        active_subnet.classifier = torch.nn.Linear(1536, nclss)\n        active_subnet = active_subnet.to(self.device)\n\n        return topol, active_subnet\n\n    def f_emb(self, dataset, net):\n        model = net        \n        module = list(model.children())[:-1]\n        model = torch.nn.Sequential(*module)\n        model.eval()\n        with torch.no_grad():\n            # Forward pass through ResNet18\n            f_emb = model(self.noise)\n        print(f_emb)\n        return f_emb\n\n\n    def train(self, model, train_loader, nclss):\n        print(f'Starting Training for:{dataset} with model topology:{topol}')\n        lr = lr\n        for ep in range((self.args.n_eps_finetuning):\n            self.curr_ep = ep\n            run_loss = 0.0\n            ep_tr_time = 0\n            total = 0\n            for b_id, batch in enumerate(self.tr_loader):\n                x,y = batch\n                b_tr_lss, b_tr_time = self.train_step(x,y)\n                run_loss += x.size(0)\n                total += x.size(0)\n                ep_tr_time += b_tr_time\n            tr_lss = run_loss/len(self.tr_dataset)\n            val_lss, val_acc, ep_val_time = self.val_train()            \n                        \n                        \n    def train_step(self,x,y)\n                        \n    def val_train(self):\n                        \n                        \n    \n    def n_param(self, model):\n        # Calculate the number of parameters in the model\n        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n    def get_query(self, dataset):\n        model = models.resneth18(pretrained = True)\n        module = list(model.children())[:-1]\n        model = torch.nn.Sequential(*module)\n        model.eval()\n        with torch.no_grad():\n            images, _ =  next(iter(self.tr_loader))\n            print(len(images))\n            # Forward pass through ResNet18\n            query_train = model(images)\n        print (query_train.shape)\n        with torch.no_grad():\n            images, _ =  next(iter(self.te_loader))\n            print(len(images))\n            # Forward pass through ResNet18\n        query_test = model(images)\n        print (query_test.shape)\n        return query_train, query_test\n\n    def save_zoo(self):\n        # Save model zoo to model_zoo.pt\n        model_zoo_dict = {\n            'dataset': self.datasets,\n            'acc': {},  # Placeholder for accuracy (fill this with values)\n            'n_params': {dataset: self.n_param(self.models[dataset]) for dataset in self.datasets},\n            'topol': {},  # Placeholder for topology information\n            'f_emb': {}  # Placeholder for feature embeddings\n        }\n        torch.save(model_zoo_dict, 'model_zoo.pt')\n\n    def save_trainpt(self):\n        # Save training instances to m_train.pt\n        trainpt_dict = {}\n        for dataset in self.datasets:\n            trainpt_dict[dataset] = {\n                'task': {},  # Placeholder for task information\n                'clss': {},  # Placeholder for class information\n                'nclss': {},  # Placeholder for number of classes\n                'x_query_train': {},  # Placeholder for training query data\n                'x_query_test': {}  # Placeholder for testing query data\n            }\n        torch.save(trainpt_dict, 'm_train.pt')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_zoo = {'dataset':['dataset1', 'dataset1', 'dataset2', 'dataset2', 'dataset3', 'dataset3'],\n             'topol':['model1', 'model2', 'model3', 'model4' , 'model5',  'model6'],\n             'acc':['acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6'],\n             'f_emb':['f_emb1', 'f_emb2', 'f_emb3', 'f_emb4', 'f_emb5', 'f_emb6'],\n             'n_params':['np1', 'np2', 'np3', 'np4', 'np5', 'np6']}","metadata":{"execution":{"iopub.status.busy":"2023-11-25T10:12:30.675070Z","iopub.execute_input":"2023-11-25T10:12:30.675459Z","iopub.status.idle":"2023-11-25T10:12:30.686881Z","shell.execute_reply.started":"2023-11-25T10:12:30.675425Z","shell.execute_reply":"2023-11-25T10:12:30.685618Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"model_zoo","metadata":{"execution":{"iopub.status.busy":"2023-11-25T10:12:33.132721Z","iopub.execute_input":"2023-11-25T10:12:33.133131Z","iopub.status.idle":"2023-11-25T10:12:33.141268Z","shell.execute_reply.started":"2023-11-25T10:12:33.133097Z","shell.execute_reply":"2023-11-25T10:12:33.140136Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"{'dataset': ['dataset1',\n  'dataset1',\n  'dataset2',\n  'dataset2',\n  'dataset3',\n  'dataset3'],\n 'topol': ['model1', 'model2', 'model3', 'model4', 'model5', 'model6'],\n 'acc': ['acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6'],\n 'f_emb': ['f_emb1', 'f_emb2', 'f_emb3', 'f_emb4', 'f_emb5', 'f_emb6'],\n 'n_params': ['np1', 'np2', 'np3', 'np4', 'np5', 'np6']}"},"metadata":{}}]},{"cell_type":"code","source":"import torch \ntorch.save(model_zoo, 'zoo.pt')","metadata":{"execution":{"iopub.status.busy":"2023-11-25T10:12:35.275130Z","iopub.execute_input":"2023-11-25T10:12:35.275500Z","iopub.status.idle":"2023-11-25T10:12:36.924288Z","shell.execute_reply.started":"2023-11-25T10:12:35.275471Z","shell.execute_reply":"2023-11-25T10:12:36.923205Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"zoo = torch.load('zoo.pt')\nprint(zoo)\nprint(type(zoo))","metadata":{"execution":{"iopub.status.busy":"2023-11-25T10:12:37.905361Z","iopub.execute_input":"2023-11-25T10:12:37.905893Z","iopub.status.idle":"2023-11-25T10:12:37.913381Z","shell.execute_reply.started":"2023-11-25T10:12:37.905858Z","shell.execute_reply":"2023-11-25T10:12:37.912176Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"{'dataset': ['dataset1', 'dataset1', 'dataset2', 'dataset2', 'dataset3', 'dataset3'], 'topol': ['model1', 'model2', 'model3', 'model4', 'model5', 'model6'], 'acc': ['acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6'], 'f_emb': ['f_emb1', 'f_emb2', 'f_emb3', 'f_emb4', 'f_emb5', 'f_emb6'], 'n_params': ['np1', 'np2', 'np3', 'np4', 'np5', 'np6']}\n<class 'dict'>\n","output_type":"stream"}]},{"cell_type":"code","source":"zoo['dataset'].append('test')\nzoo['topol'].append('test')\nzoo['acc'].append('test')\nzoo['f_emb'].append('test')\nzoo['n_params'].append('test')\nprint(zoo)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T10:13:25.412527Z","iopub.execute_input":"2023-11-25T10:13:25.412996Z","iopub.status.idle":"2023-11-25T10:13:25.419464Z","shell.execute_reply.started":"2023-11-25T10:13:25.412953Z","shell.execute_reply":"2023-11-25T10:13:25.418564Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"{'dataset': ['dataset1', 'dataset1', 'dataset2', 'dataset2', 'dataset3', 'dataset3', 'test'], 'topol': ['model1', 'model2', 'model3', 'model4', 'model5', 'model6', 'test'], 'acc': ['acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'test'], 'f_emb': ['f_emb1', 'f_emb2', 'f_emb3', 'f_emb4', 'f_emb5', 'f_emb6', 'test'], 'n_params': ['np1', 'np2', 'np3', 'np4', 'np5', 'np6', 'test']}\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}