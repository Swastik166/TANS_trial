{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7046063,"sourceType":"datasetVersion","datasetId":4054560},{"sourceId":7051954,"sourceType":"datasetVersion","datasetId":4058600}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/Swastik166/TANS_trial.git\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.insert(0, './TANS_trial')\n!pip install config","metadata":{"execution":{"iopub.status.busy":"2023-11-25T18:21:43.473272Z","iopub.execute_input":"2023-11-25T18:21:43.473632Z","iopub.status.idle":"2023-11-25T18:21:55.468344Z","shell.execute_reply.started":"2023-11-25T18:21:43.473603Z","shell.execute_reply":"2023-11-25T18:21:55.466976Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting config\n  Downloading config-0.5.1-py2.py3-none-any.whl (20 kB)\nInstalling collected packages: config\nSuccessfully installed config-0.5.1\n","output_type":"stream"}]},{"cell_type":"code","source":"%%bash\ncd TANS_trial\npython3 main.py --gpu 0 --mode train --batch-size 140 --n-epochs 10000 --base-path path/for/storing/outcomes/ --data-path path/to/processed/dataset/is/stored/ --model-zoo path/to/model_zoo.pt --seed 777 ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nimport numpy as np\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nimport os\nfrom PIL import Image\n\nbatch_size = 32\ndata_path = '/kaggle/input/ie-643-tans-train-sub-dataset'\n\n\n'''def get_loader(mode='train'):\n    dataset = ZooDatasets(mode=mode)\n    root_path = dataset.load_data()\n    loader = ImageFolder(root=root_path,transform=transforms.Compose([\n                                                  transforms.Resize((224, 224)),\n                                                  transforms.ToTensor(),\n                                              ]),\n                                              )\n    loader = DataLoader(dataset=loader,\n                        batch_size=batch_size,\n                        shuffle=(mode == 'train'),\n                        num_workers=4)\n    return dataset, loader'''\n\n\nclass ZooDatasets(Dataset):\n    \n    def __init__(self, mode='train', transform=None):\n        #self.args = args\n        self.mode = mode\n        self.transform = transform\n        self.data_path = data_path\n        '''self.dataset_list = [\n                'bottles',\n                'cassava_leaf_disease',\n                'casting_products',\n                'corals',\n                'ct_images',\n                'four_shapes',\n                'fruits',\n                'lego_bricks',\n                'natural_images',\n                'store_items',\n        ]'''\n        self.dataset_list = ['corals','lego_bricks']\n        \n        self.curr_dataset = self.dataset_list[0]\n        self.load_data()\n\n\n              \n        \n    def get_loader(self, mode='train'):\n        root_path = self.load_data()\n        loader = ImageFolder(root=root_path, transform=transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n        ]))\n\n        loader = DataLoader(\n            dataset=loader,\n            batch_size=batch_size,\n            shuffle=(mode == 'train'),\n            num_workers=4\n        )\n        \n        return loader\n        \n    def load_data(self):\n        if self.mode == 'train':\n            self.data_folder = os.path.join(self.data_path, f'{self.curr_dataset}/tr')\n        elif self.mode == 'validation':\n            self.data_folder = os.path.join(self.data_path, f'{self.curr_dataset}/va')\n        elif self.mode == 'test':\n            self.data_folder = os.path.join(self.data_path, f'{self.curr_dataset}/te')\n            \n            \n        self.classes = sorted([d.name for d in os.scandir(self.data_folder) if d.is_dir()])\n        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n        self.samples = []\n        \n        for target_class in self.classes:\n            class_index = self.class_to_idx[target_class]\n            target_dir = os.path.join(self.data_folder, target_class)\n            for root, _, fnames in sorted(os.walk(target_dir, followlinks=True)):\n                for fname in sorted(fnames):\n                    path = os.path.join(root, fname)\n                    # Modify here to convert label to integer\n                    label = self.class_to_idx[target_class]\n                    self.samples.append((path, label))\n        \n        \n        return self.data_folder\n        \n     \n        \n    def get_dataset_list(self):\n        return self.dataset_list\n    \n    \n    def curr(self):\n        return self.curr_dataset\n    \n    def set_mode(self, mode):\n        self.mode = mode\n        \n    \n    def __len__(self):\n        return len(self.samples)\n    \n    def __getitem__(self, index):\n        path, target = self.samples[index]\n        img = Image.open(path).convert('RGB')\n\n        if self.transform is not None:\n            img = self.transform(img)\n            \n\n        return img, target\n    \n    \n    def set_dataset(self, dataset):\n        self.curr_dataset = dataset\n        self.load_data()\n            \n    def get_nclss(self):\n        return (len(self.classes))\n    \n    def get_clss(self):\n        return (self.classes)\n        ","metadata":{"execution":{"iopub.status.busy":"2023-11-26T15:13:04.759653Z","iopub.execute_input":"2023-11-26T15:13:04.759918Z","iopub.status.idle":"2023-11-26T15:13:08.479907Z","shell.execute_reply.started":"2023-11-26T15:13:04.759894Z","shell.execute_reply":"2023-11-26T15:13:08.478919Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"tr_dataset = ZooDatasets(mode='train')\nte_dataset = ZooDatasets(mode='test')\nval_dataset = ZooDatasets(mode='validation')\n\n'''intr_loader = intr_dataset.get_loader(mode='train')\ninte_loader = inte_dataset.get_loader(mode='test')\ninval_loader = inval_dataset.get_loader(mode='validation')'''\n\nprint('outer', tr_dataset.curr_dataset)\n\nfor query_dataset in tr_dataset.get_dataset_list():\n    print('quesry_dataset',query_dataset)\n    tr_dataset.set_dataset(query_dataset)\n    te_dataset.set_dataset(query_dataset)\n    val_dataset.set_dataset(query_dataset)\n    \n    tr_loader = tr_dataset.get_loader(mode='train')\n    te_loader = te_dataset.get_loader(mode='test')\n    val_loader = val_dataset.get_loader(mode='validation')\n    \n    \n    print(tr_dataset.curr_dataset)\n    x, y = next(iter(tr_loader))\n    print('y for tr', x.shape)\n    x, y = next(iter(te_loader))\n    print('y for te', y)\n    \n    clss = tr_dataset.get_clss()\n    nclss = tr_dataset.get_nclss()\n    \n    print('nclass', nclss )\n    print('clss', clss )\n    \n\n    print('tr_loader', len(tr_loader)*batch_size)\n    print('te_loader', len(te_loader)*batch_size)\n    print('val_loader', len(val_loader)*batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T22:26:41.466238Z","iopub.execute_input":"2023-11-25T22:26:41.466973Z","iopub.status.idle":"2023-11-25T22:26:42.502581Z","shell.execute_reply.started":"2023-11-25T22:26:41.466928Z","shell.execute_reply":"2023-11-25T22:26:42.501521Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"outer corals\nquesry_dataset corals\ncorals\ny for tr torch.Size([32, 3, 224, 224])\ny for te tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3,\n        3, 3, 3, 4, 4, 5, 5, 5])\nnclass 14\nclss ['ACER', 'APAL', 'CNAT', 'DANT', 'DSTR', 'GORG', 'MALC', 'MCAV', 'MMEA', 'MONT', 'PALY', 'SPO', 'SSID', 'TUNI']\ntr_loader 512\nte_loader 96\nval_loader 64\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport random\nimport torchvision.models as models\nfrom tqdm import tqdm\nimport time\n!pip install gdown\n\n\"\"\"add utils from misc and use the finctions available in for better error handling\"\"\"\n\nnoise_path = '/kaggle/working/noise.pt'\nlearn = 1e-2\npatience = 5\nn_eps_finetuning = 5\n\nclass ModelZoo:\n    def __init__(self):\n        self.seed = 777\n        self.models = {}\n        self.train_instances = {}\n        self.trainpt_dict ={}\n        \n        self.noise = torch.load(noise_path)\n        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n        torch.cuda.manual_seed(self.seed)\n        torch.manual_seed(self.seed)\n        np.random.seed(self.seed)\n        random.seed(self.seed)\n\n\n        \n        \n    def init_loaders(self):\n        # Get loaders for train, test, and validation data\n        print('\\n=====> LOADING dataset and loaders for train, test and validation <=====\\n')\n       \n        \n        self.tr_dataset = ZooDatasets(mode='train')\n        self.te_dataset = ZooDatasets(mode='test')\n        self.val_dataset = ZooDatasets(mode='validation')\n        \n        \n        \n        \n        \n        \n    def create_zoo(self):\n        zoo = { 'dataset': [],\n                 'topol': [],\n                    'f_emb': [],\n                   'acc': [],\n                   'n_params':[]\n            \n        }\n        \n        \n        self.init_loaders()\n\n            \n            \n        for query_dataset in self.tr_dataset.get_dataset_list():\n            \n            \n            \n            print('quesry_dataset',query_dataset)\n            \n            self.tr_dataset.set_dataset(query_dataset)\n            self.te_dataset.set_dataset(query_dataset)\n            self.val_dataset.set_dataset(query_dataset)\n\n            tr_loader = self.tr_dataset.get_loader(mode='train')\n            te_loader = self.te_dataset.get_loader(mode='test')\n            val_loader = self.val_dataset.get_loader(mode='validation')\n            nclass = self.tr_dataset.get_nclss()\n            print(f\"\\nDataset : {query_dataset}, nclss:{nclass}\\n\")\n            \n            \n            \n\n\n            for i in range(3):\n                # Get neural network model and topology information\n                print(f'\\n=====> Generating {i+1}th network  <=====\\n')\n                topol, net = self.get_net(nclass)\n\n                # Training the model and obtaining accuracy\n                lss = torch.nn.CrossEntropyLoss()\n                optim = torch.optim.SGD(net.parameters(), lr=1e-2, momentum=0.9, weight_decay=4e-5)\n                scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim , float(n_eps_finetuning))\n                \n                acc = self.train( net, optim, scheduler, lss, query_dataset, tr_loader, val_loader, nclass, topol)  # Assuming train method returns accuracy\n\n                # Calculating number of parameters\n                n_params = self.n_param(net)\n                f_emb = self.f_emb(net)\n\n                \n                del net\n                del optim\n                del lss\n                \n                zoo['dataset'].append(query_dataset)\n                zoo['topol'].append(topol)\n                zoo['acc'].append(acc)\n                zoo['f_emb'].append(f_emb)\n                zoo['n_params'].append(n_params)\n                \n                print(zoo)\n                \n            x_query_train, x_query_test = self.get_query(tr_loader, te_loader)\n            print(f'x_query:{len(x_query_train)}, x_query-test :{len(x_query_test)}')\n            clss = self.tr_dataset.get_clss()\n            self.save_trainpt(query_dataset, clss, nclass, x_query_test, x_query_train)\n                \n        self.save_zoo(zoo)\n        \n                \n                \n\n\n    def get_net(self, nclss):\n        print(\"\\n=====>Generating sub_net<=====\\n\")\n        super_net_name = \"ofa_supernet_mbv3_w12\"\n\n        # Load the super network from the 'mit-han-lab/once-for-all' repository\n        super_net = torch.hub.load('mit-han-lab/once-for-all', super_net_name, pretrained=True).eval()\n\n        # Sample an active subnet configuration from the super network\n        sampled_config = super_net.sample_active_subnet()\n\n        # Extract topology information from the sampled configuration\n        pre_topol = list(sampled_config.values())\n        topol = []\n\n        for i in pre_topol:\n            for j in i:\n                topol.append(j)\n\n        # Split the topology into kernel sizes, expansion ratios, and depths\n        ks = topol[:20] \n        e = topol[20:40]\n        d = topol[40:]\n\n        # Set the active subnet in the super network using the sampled topology\n        super_net.set_active_subnet(ks=ks, e=e, d=d)\n        active_subnet = super_net.get_active_subnet(preserve_weight=True)\n        active_subnet.classifier = torch.nn.Linear(1536, nclss)\n        active_subnet = active_subnet.to(self.device)\n\n        return topol, active_subnet\n\n    \n    \n    \n        '''def f_emb(self, net):\n        print(\"=====>Generating f_emb<=====\")\n        model = net\n        model.to(self.device)\n        modules = list(model.children())\n        last_valid_module = None\n\n        # Find the last valid module with a defined forward function\n        for module in reversed(modules):\n            if hasattr(module, 'forward'):\n                last_valid_module = module\n                break\n\n        if last_valid_module is None:\n            raise NotImplementedError(\"No valid module with a 'forward' function found.\")\n\n        # Remove the last layer (classifier)\n        modified_model = torch.nn.Sequential(*modules[:-1]) if len(modules) > 1 else last_valid_module\n\n        modified_model.eval()\n        with torch.no_grad():\n            # Forward pass through the modified model\n            noise = self.noise.to(self.device)\n            f_emb = modified_model(noise)\n        print(f_emb)\n        return f_emb'''\n        \n        \n\n        \n\n    def f_emb(self, net):\n        print(\"\\n=====>Generating f_emb<=====\\n\")\n        model = net\n        model.to(self.device)\n        layer = model.feature_mix_layer\n        \n        def copy_embeddings(module, input, output):\n            # Assuming the output shape is (batch_size, channels, height, width)\n            embeddings = output.squeeze()  # Remove dimensions of size 1\n            outputs.append(embeddings.cpu().detach().numpy())\n\n\n        outputs = []\n        _ = layer.register_forward_hook(copy_embeddings)\n\n        model.eval()\n        noise = self.noise.to(self.device)\n        _ = model(noise)\n        f_emb = outputs[-1]\n        f_emb = torch.tensor(f_emb)\n        del outputs\n        print(f_emb.shape)\n        return f_emb\n    \n    \n    \n\n    def train(self, model, optim, scheduler, lss, dataset, train_loader, val_loader, nclss, topol):\n        print(\"\\n=====> Training started <=====\\n\")\n        #self.model = model\n        print(f'Starting Training for:{dataset} with model topology:{topol}')\n        lr = learn\n        counter = 0\n        best_val_loss = 10000\n        val_acc = list()\n        \n        \n        for ep in range(n_eps_finetuning):\n            curr_ep = ep\n            ep_loss_tr = 0.0\n            ep_loss_val = 0.0\n            ep_tr_time = 0\n            st = time.time()\n            \n            \n            model.train()\n            for b_id, batch in tqdm(enumerate(train_loader)):\n                optim.zero_grad()\n                \n                x,y = batch\n                output = model(x.to(self.device))\n                loss = lss(output, y.to(self.device))\n                loss.backward()\n                optim.step()\n                scheduler.step()\n                        \n                tr_loss = loss.item()\n                        \n                ep_loss_tr += tr_loss * x.size(0)\n                \n            ep_loss_tr = ep_loss_tr/len(train_loader)\n\n                        \n            model.eval()\n            total_val = 0\n            correct_val = 0\n                        \n                        \n            for v_id, (x,y) in tqdm(enumerate(val_loader)):\n                outputs = model(x.to(self.device))\n                loss_v = lss(outputs, y.to(self.device))\n                       \n                val_loss = loss_v.item()\n                \n                ep_loss_val += val_loss * x.size(0)\n                        \n                pred = torch.argmax(outputs, dim = 1)\n                total_val += y.size(0)\n                correct_val += (pred == y.to(self.device)).sum().item() \n                        \n            acc = (100*correct_val)/total_val\n            val_acc.append(acc)\n            ep_loss_val = ep_loss_val/len(val_loader)\n            dura = time.time() -st \n            \n            print('\\nEpoch: {}/{}, Train Loss: {:.8f} , Val Loss: {:.8f}, Val Accuracy: {:.8f}, Time: {:.8f}'.format(ep + 1, n_eps_finetuning, ep_loss_tr, ep_loss_val, acc, dura))\n            \n            \n    \n            if ep_loss_val < best_val_loss:\n                best_val_loss = ep_loss_tr\n                counter = 0\n                \n            else:\n                counter += 1\n                \n            if counter >= patience:\n                print(f\"Early stopping on, {ep}th, epoch\")\n                break\n               \n            #print(f'ep : {ep}, loss:{ep_loss_tr}, val_loss:{ep_loss_val}, acc:{acc}, time:{dura}')\n                \n        return val_acc[-1]\n            \n            \n                        \n                        \n                        \n                        \n    \n    def n_param(self, model):\n        # Calculate the number of parameters in the model\n        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n    \n    \n\n    def get_query(self, train_loader, test_loader):\n        print(\"\\n=====> GENERATING QUERIES <=====\\n\")\n        model = models.resnet18(pretrained=True)\n        layer = model._modules.get('avgpool')\n\n        def copy_embeddings(m, i, o):\n            \"\"\"Copy embeddings from the penultimate layer.\"\"\"\n            o = o[:, :, 0, 0].detach().numpy().tolist()\n            outputs.append(o)\n\n        outputs = []\n        # attach hook to the penultimate layer\n        _ = layer.register_forward_hook(copy_embeddings)\n\n        model.eval()\n        X, y = next(iter(train_loader))\n        _ = model(X)\n\n        list_embeddings = [item for sublist in outputs for item in sublist]\n\n        query_train = []\n        for a in list_embeddings:\n            a = torch.tensor(a)\n            query_train.append(a)\n\n        print(f'query_shape_train: {len(query_train)}, each tensor:{query_train[0].shape}')\n\n        outputs = []\n        list_embeddings = []\n\n        model.eval()\n\n        X, y = next(iter(test_loader))\n        _ = model(X)\n\n        list_embeddings = [item for sublist in outputs for item in sublist]\n\n        query_test = []\n        for a in list_embeddings:\n            a = torch.tensor(a)\n            query_test.append(a)\n\n        print(f'query_shape_test: {len(query_test)}, each tensor:{query_test[0].shape}')\n        del outputs\n        del list_embeddings\n        return query_train, query_test\n    \n    '''def get_query(self, train_loader, test_loader):\n        print(\"\\n=====>GENERATING QUERIES<=====\\n\")\n        model = models.resnet18(pretrained=True)\n        module = list(model.children())[:-1]\n        model = torch.nn.Sequential(*module)\n        model.eval()\n        \n        with torch.no_grad():\n            for X, y in train_loader:\n                query_train = model(X)\n                query_train = torch.squeeze(query_train)\n                break  # Exit loop after processing the first batch\n\n        print(f'query_train_shape: {query_train.shape}')\n\n        with torch.no_grad():\n            for X, y in test_loader:\n                query_test = model(X)\n                query_test = torch.squeeze(query_test)\n                break  # Exit loop after processing the first batch\n\n        print(f'query_test_shape: {query_test.shape}')\n\n        return query_train, query_test'''\n    \n    \n    \n\n    def save_zoo(self, dict):\n        # Save model zoo to model_zoo.pt\n        print(f'\\n=====>SAVING {dict} in model_zoo.pt <=====\\n')\n\n        torch.save(dict, 'model_zoo.pt')\n\n        \n        \n    def save_trainpt(self, dataset, clss, nclss, x_test, x_train) :\n        # Save training instances to m_train.pt\n        print(f'\\n=====>SAVING {dataset} in m_train.pt <=====\\n')\n        temp = {}\n        temp['task'] = dataset\n        temp['clss'] = clss\n        temp['nclss'] = nclss\n        temp['x_query_test'] = x_test\n        temp['x_query_train'] = x_train\n        \n        self.trainpt_dict[dataset] = temp\n        \n\n        torch.save(self.trainpt_dict, 'meta_train.pt')\n","metadata":{"execution":{"iopub.status.busy":"2023-11-26T15:13:08.481738Z","iopub.execute_input":"2023-11-26T15:13:08.482171Z","iopub.status.idle":"2023-11-26T15:13:21.006399Z","shell.execute_reply.started":"2023-11-26T15:13:08.482144Z","shell.execute_reply":"2023-11-26T15:13:21.005254Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting gdown\n  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.12.2)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.31.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from gdown) (1.16.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.1)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2023.7.22)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nInstalling collected packages: gdown\nSuccessfully installed gdown-4.7.1\n","output_type":"stream"}]},{"cell_type":"code","source":"zoo = ModelZoo()\nzoo.create_zoo()","metadata":{"execution":{"iopub.status.busy":"2023-11-26T15:13:32.299736Z","iopub.execute_input":"2023-11-26T15:13:32.300662Z","iopub.status.idle":"2023-11-26T15:21:10.861688Z","shell.execute_reply.started":"2023-11-26T15:13:32.300619Z","shell.execute_reply":"2023-11-26T15:21:10.860488Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"\n=====> LOADING dataset and loaders for train, test and validation <=====\n\nquesry_dataset corals\n\nDataset : corals, nclss:14\n\n\n=====> Generating 1th network  <=====\n\n\n=====>Generating sub_net<=====\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/hub.py:286: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n  warnings.warn(\nDownloading: \"https://github.com/mit-han-lab/once-for-all/zipball/master\" to /root/.cache/torch/hub/master.zip\nDownloading: \"https://raw.githubusercontent.com/han-cai/files/master/ofa/ofa_nets/ofa_mbv3_d234_e346_k357_w1.2\" to .torch/ofa_nets/ofa_mbv3_d234_e346_k357_w1.2\n","output_type":"stream"},{"name":"stdout","text":"\n=====> Training started <=====\n\nStarting Training for:corals with model topology:[3, 5, 5, 5, 7, 5, 5, 7, 3, 5, 7, 7, 7, 5, 7, 5, 3, 3, 7, 3, 4, 3, 6, 3, 6, 6, 4, 4, 6, 4, 3, 6, 6, 3, 4, 6, 3, 4, 6, 3, 3, 4, 2, 4, 4]\n","output_type":"stream"},{"name":"stderr","text":"16it [00:08,  1.83it/s]\n2it [00:00,  5.04it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 1/5, Train Loss: 73.23685668 , Val Loss: 69.62717223, Val Accuracy: 51.61290323, Time: 9.36200190\n","output_type":"stream"},{"name":"stderr","text":"\n16it [00:02,  5.68it/s]\n2it [00:00,  7.07it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 2/5, Train Loss: 46.13393561 , Val Loss: 40.27857423, Val Accuracy: 72.58064516, Time: 3.31475091\n","output_type":"stream"},{"name":"stderr","text":"\n16it [00:02,  5.62it/s]\n2it [00:00,  7.35it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 3/5, Train Loss: 21.76699058 , Val Loss: 24.19290197, Val Accuracy: 83.87096774, Time: 3.34537053\n","output_type":"stream"},{"name":"stderr","text":"\n16it [00:02,  5.59it/s]\n2it [00:00,  6.56it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 4/5, Train Loss: 9.64565520 , Val Loss: 12.55820280, Val Accuracy: 87.09677419, Time: 3.38856483\n","output_type":"stream"},{"name":"stderr","text":"\n16it [00:02,  5.64it/s]\n2it [00:00,  7.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 5/5, Train Loss: 5.41209367 , Val Loss: 11.25670427, Val Accuracy: 91.93548387, Time: 3.34463978\n\n=====>Generating f_emb<=====\n\ntorch.Size([1536])\n{'dataset': ['corals'], 'topol': [[3, 5, 5, 5, 7, 5, 5, 7, 3, 5, 7, 7, 7, 5, 7, 5, 3, 3, 7, 3, 4, 3, 6, 3, 6, 6, 4, 4, 6, 4, 3, 6, 6, 3, 4, 6, 3, 4, 6, 3, 3, 4, 2, 4, 4]], 'f_emb': [tensor([ 0.0133, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.3036])], 'acc': [91.93548387096774], 'n_params': [6234590]}\n\n=====> Generating 2th network  <=====\n\n\n=====>Generating sub_net<=====\n\n","output_type":"stream"},{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/mit-han-lab_once-for-all_master\n","output_type":"stream"},{"name":"stdout","text":"\n=====> Training started <=====\n\nStarting Training for:corals with model topology:[3, 7, 7, 7, 5, 7, 5, 3, 7, 5, 3, 3, 5, 5, 3, 7, 7, 5, 3, 5, 3, 4, 6, 3, 6, 4, 6, 4, 4, 3, 3, 3, 3, 6, 6, 3, 3, 4, 6, 4, 4, 3, 2, 2, 4]\n","output_type":"stream"},{"name":"stderr","text":"16it [00:02,  5.48it/s]\n2it [00:00,  6.58it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 1/5, Train Loss: 74.37357995 , Val Loss: 72.05577064, Val Accuracy: 37.09677419, Time: 3.45953584\n","output_type":"stream"},{"name":"stderr","text":"\n16it [00:02,  5.56it/s]\n2it [00:00,  6.65it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 2/5, Train Loss: 47.52944600 , Val Loss: 41.31765723, Val Accuracy: 75.80645161, Time: 3.40550923\n","output_type":"stream"},{"name":"stderr","text":"\n16it [00:02,  5.53it/s]\n2it [00:00,  6.92it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 3/5, Train Loss: 21.65656362 , Val Loss: 22.54259306, Val Accuracy: 82.25806452, Time: 3.41781402\n","output_type":"stream"},{"name":"stderr","text":"\n16it [00:02,  5.52it/s]\n2it [00:00,  7.01it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 4/5, Train Loss: 10.02466434 , Val Loss: 18.18449628, Val Accuracy: 85.48387097, Time: 3.42119050\n","output_type":"stream"},{"name":"stderr","text":"\n16it [00:02,  5.53it/s]\n2it [00:00,  6.76it/s]\nUsing cache found in /root/.cache/torch/hub/mit-han-lab_once-for-all_master\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 5/5, Train Loss: 5.49737221 , Val Loss: 13.61488447, Val Accuracy: 88.70967742, Time: 3.43022394\n\n=====>Generating f_emb<=====\n\ntorch.Size([1536])\n{'dataset': ['corals', 'corals'], 'topol': [[3, 5, 5, 5, 7, 5, 5, 7, 3, 5, 7, 7, 7, 5, 7, 5, 3, 3, 7, 3, 4, 3, 6, 3, 6, 6, 4, 4, 6, 4, 3, 6, 6, 3, 4, 6, 3, 4, 6, 3, 3, 4, 2, 4, 4], [3, 7, 7, 7, 5, 7, 5, 3, 7, 5, 3, 3, 5, 5, 3, 7, 7, 5, 3, 5, 3, 4, 6, 3, 6, 4, 6, 4, 4, 3, 3, 3, 3, 6, 6, 3, 3, 4, 6, 4, 4, 3, 2, 2, 4]], 'f_emb': [tensor([ 0.0133, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.3036]), tensor([-0.3080, -0.3462, -0.1965,  ..., -0.2554, -0.2233, -0.3557])], 'acc': [91.93548387096774, 88.70967741935483], 'n_params': [6234590, 5631262]}\n\n=====> Generating 3th network  <=====\n\n\n=====>Generating sub_net<=====\n\n\n=====> Training started <=====\n\nStarting Training for:corals with model topology:[3, 7, 5, 5, 3, 7, 7, 5, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 5, 7, 6, 6, 6, 3, 6, 3, 4, 4, 6, 6, 6, 4, 3, 6, 4, 6, 6, 4, 6, 4, 2, 3, 3, 3, 4]\n","output_type":"stream"},{"name":"stderr","text":"16it [00:02,  5.56it/s]\n2it [00:00,  6.78it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 1/5, Train Loss: 74.44131614 , Val Loss: 71.72178388, Val Accuracy: 38.70967742, Time: 3.41467977\n","output_type":"stream"},{"name":"stderr","text":"\n16it [00:02,  5.61it/s]\n2it [00:00,  7.02it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 2/5, Train Loss: 59.48820434 , Val Loss: 69.37748289, Val Accuracy: 38.70967742, Time: 3.38922501\n","output_type":"stream"},{"name":"stderr","text":"\n16it [00:02,  5.61it/s]\n2it [00:00,  6.90it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 3/5, Train Loss: 43.99121922 , Val Loss: 211.14500117, Val Accuracy: 40.32258065, Time: 3.40316391\n","output_type":"stream"},{"name":"stderr","text":"\n16it [00:02,  5.60it/s]\n2it [00:00,  6.60it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 4/5, Train Loss: 30.55592264 , Val Loss: 61.04600823, Val Accuracy: 64.51612903, Time: 3.39110470\n","output_type":"stream"},{"name":"stderr","text":"\n16it [00:02,  5.59it/s]\n2it [00:00,  6.88it/s]\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 5/5, Train Loss: 16.79252392 , Val Loss: 23.56044358, Val Accuracy: 80.64516129, Time: 3.39915180\n\n=====>Generating f_emb<=====\n\ntorch.Size([1536])\n{'dataset': ['corals', 'corals', 'corals'], 'topol': [[3, 5, 5, 5, 7, 5, 5, 7, 3, 5, 7, 7, 7, 5, 7, 5, 3, 3, 7, 3, 4, 3, 6, 3, 6, 6, 4, 4, 6, 4, 3, 6, 6, 3, 4, 6, 3, 4, 6, 3, 3, 4, 2, 4, 4], [3, 7, 7, 7, 5, 7, 5, 3, 7, 5, 3, 3, 5, 5, 3, 7, 7, 5, 3, 5, 3, 4, 6, 3, 6, 4, 6, 4, 4, 3, 3, 3, 3, 6, 6, 3, 3, 4, 6, 4, 4, 3, 2, 2, 4], [3, 7, 5, 5, 3, 7, 7, 5, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 5, 7, 6, 6, 6, 3, 6, 3, 4, 4, 6, 6, 6, 4, 3, 6, 4, 6, 6, 4, 6, 4, 2, 3, 3, 3, 4]], 'f_emb': [tensor([ 0.0133, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.3036]), tensor([-0.3080, -0.3462, -0.1965,  ..., -0.2554, -0.2233, -0.3557]), tensor([0.3410, -0.0000, -0.0000,  ..., -0.0000, -0.0000, 0.1439])], 'acc': [91.93548387096774, 88.70967741935483, 80.64516129032258], 'n_params': [6234590, 5631262, 6576438]}\n\n=====> GENERATING QUERIES <=====\n\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 167MB/s] \n","output_type":"stream"},{"name":"stdout","text":"query_shape_train: 32, each tensor:torch.Size([512])\nquery_shape_test: 32, each tensor:torch.Size([512])\nx_query:32, x_query-test :32\n\n=====>SAVING corals in m_train.pt <=====\n\nquesry_dataset lego_bricks\n\nDataset : lego_bricks, nclss:16\n\n\n=====> Generating 1th network  <=====\n\n\n=====>Generating sub_net<=====\n\n","output_type":"stream"},{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/mit-han-lab_once-for-all_master\n","output_type":"stream"},{"name":"stdout","text":"\n=====> Training started <=====\n\nStarting Training for:lego_bricks with model topology:[7, 5, 3, 3, 5, 3, 5, 5, 5, 5, 3, 7, 7, 5, 7, 3, 3, 5, 3, 5, 3, 4, 6, 6, 6, 3, 6, 3, 6, 3, 6, 4, 4, 6, 6, 4, 6, 6, 6, 4, 2, 2, 2, 3, 2]\n","output_type":"stream"},{"name":"stderr","text":"160it [00:21,  7.60it/s]\n20it [00:01, 14.20it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 1/5, Train Loss: 34.53208502 , Val Loss: 9.43179991, Val Accuracy: 92.00626959, Time: 22.72587132\n","output_type":"stream"},{"name":"stderr","text":"\n160it [00:20,  7.68it/s]\n20it [00:01, 18.31it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 2/5, Train Loss: 5.51983828 , Val Loss: 2.86556287, Val Accuracy: 96.70846395, Time: 22.26392412\n","output_type":"stream"},{"name":"stderr","text":"\n160it [00:20,  7.69it/s]\n20it [00:01, 18.69it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 3/5, Train Loss: 2.58671267 , Val Loss: 2.96559230, Val Accuracy: 95.92476489, Time: 22.14848471\n","output_type":"stream"},{"name":"stderr","text":"\n160it [00:20,  7.73it/s]\n20it [00:01, 18.76it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 4/5, Train Loss: 1.65639136 , Val Loss: 1.49777090, Val Accuracy: 98.27586207, Time: 22.04146385\n","output_type":"stream"},{"name":"stderr","text":"\n160it [00:20,  7.72it/s]\n20it [00:01, 18.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 5/5, Train Loss: 0.87441760 , Val Loss: 0.96470117, Val Accuracy: 98.58934169, Time: 22.08690310\n\n=====>Generating f_emb<=====\n\ntorch.Size([1536])\n{'dataset': ['corals', 'corals', 'corals', 'lego_bricks'], 'topol': [[3, 5, 5, 5, 7, 5, 5, 7, 3, 5, 7, 7, 7, 5, 7, 5, 3, 3, 7, 3, 4, 3, 6, 3, 6, 6, 4, 4, 6, 4, 3, 6, 6, 3, 4, 6, 3, 4, 6, 3, 3, 4, 2, 4, 4], [3, 7, 7, 7, 5, 7, 5, 3, 7, 5, 3, 3, 5, 5, 3, 7, 7, 5, 3, 5, 3, 4, 6, 3, 6, 4, 6, 4, 4, 3, 3, 3, 3, 6, 6, 3, 3, 4, 6, 4, 4, 3, 2, 2, 4], [3, 7, 5, 5, 3, 7, 7, 5, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 5, 7, 6, 6, 6, 3, 6, 3, 4, 4, 6, 6, 6, 4, 3, 6, 4, 6, 6, 4, 6, 4, 2, 3, 3, 3, 4], [7, 5, 3, 3, 5, 3, 5, 5, 5, 5, 3, 7, 7, 5, 7, 3, 3, 5, 3, 5, 3, 4, 6, 6, 6, 3, 6, 3, 6, 3, 6, 4, 4, 6, 6, 4, 6, 6, 6, 4, 2, 2, 2, 3, 2]], 'f_emb': [tensor([ 0.0133, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.3036]), tensor([-0.3080, -0.3462, -0.1965,  ..., -0.2554, -0.2233, -0.3557]), tensor([0.3410, -0.0000, -0.0000,  ..., -0.0000, -0.0000, 0.1439]), tensor([-0., -0., -0.,  ..., -0., -0., -0.])], 'acc': [91.93548387096774, 88.70967741935483, 80.64516129032258, 98.58934169278997], 'n_params': [6234590, 5631262, 6576438, 5356576]}\n\n=====> Generating 2th network  <=====\n\n\n=====>Generating sub_net<=====\n\n","output_type":"stream"},{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/mit-han-lab_once-for-all_master\n","output_type":"stream"},{"name":"stdout","text":"\n=====> Training started <=====\n\nStarting Training for:lego_bricks with model topology:[3, 5, 5, 7, 5, 5, 7, 3, 7, 5, 5, 5, 3, 5, 3, 7, 5, 7, 7, 3, 3, 6, 3, 3, 6, 3, 6, 6, 4, 4, 3, 4, 4, 3, 6, 6, 4, 3, 4, 3, 4, 3, 4, 4, 4]\n","output_type":"stream"},{"name":"stderr","text":"160it [00:28,  5.61it/s]\n20it [00:01, 14.68it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 1/5, Train Loss: 31.37605624 , Val Loss: 5.69940069, Val Accuracy: 94.82758621, Time: 30.12966609\n","output_type":"stream"},{"name":"stderr","text":"\n160it [00:28,  5.62it/s]\n20it [00:01, 14.18it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 2/5, Train Loss: 4.33270592 , Val Loss: 2.66548464, Val Accuracy: 97.96238245, Time: 30.17074800\n","output_type":"stream"},{"name":"stderr","text":"\n160it [00:28,  5.61it/s]\n20it [00:01, 14.08it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 3/5, Train Loss: 1.99124088 , Val Loss: 1.67784903, Val Accuracy: 98.11912226, Time: 30.26852202\n","output_type":"stream"},{"name":"stderr","text":"\n160it [00:28,  5.60it/s]\n20it [00:01, 14.05it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 4/5, Train Loss: 0.77395547 , Val Loss: 1.13039259, Val Accuracy: 98.58934169, Time: 30.24453592\n","output_type":"stream"},{"name":"stderr","text":"\n160it [00:28,  5.62it/s]\n20it [00:01, 14.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 5/5, Train Loss: 0.51637158 , Val Loss: 0.58574837, Val Accuracy: 99.52978056, Time: 30.17777038\n\n=====>Generating f_emb<=====\n\ntorch.Size([1536])\n{'dataset': ['corals', 'corals', 'corals', 'lego_bricks', 'lego_bricks'], 'topol': [[3, 5, 5, 5, 7, 5, 5, 7, 3, 5, 7, 7, 7, 5, 7, 5, 3, 3, 7, 3, 4, 3, 6, 3, 6, 6, 4, 4, 6, 4, 3, 6, 6, 3, 4, 6, 3, 4, 6, 3, 3, 4, 2, 4, 4], [3, 7, 7, 7, 5, 7, 5, 3, 7, 5, 3, 3, 5, 5, 3, 7, 7, 5, 3, 5, 3, 4, 6, 3, 6, 4, 6, 4, 4, 3, 3, 3, 3, 6, 6, 3, 3, 4, 6, 4, 4, 3, 2, 2, 4], [3, 7, 5, 5, 3, 7, 7, 5, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 5, 7, 6, 6, 6, 3, 6, 3, 4, 4, 6, 6, 6, 4, 3, 6, 4, 6, 6, 4, 6, 4, 2, 3, 3, 3, 4], [7, 5, 3, 3, 5, 3, 5, 5, 5, 5, 3, 7, 7, 5, 7, 3, 3, 5, 3, 5, 3, 4, 6, 6, 6, 3, 6, 3, 6, 3, 6, 4, 4, 6, 6, 4, 6, 6, 6, 4, 2, 2, 2, 3, 2], [3, 5, 5, 7, 5, 5, 7, 3, 7, 5, 5, 5, 3, 5, 3, 7, 5, 7, 7, 3, 3, 6, 3, 3, 6, 3, 6, 6, 4, 4, 3, 4, 4, 3, 6, 6, 4, 3, 4, 3, 4, 3, 4, 4, 4]], 'f_emb': [tensor([ 0.0133, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.3036]), tensor([-0.3080, -0.3462, -0.1965,  ..., -0.2554, -0.2233, -0.3557]), tensor([0.3410, -0.0000, -0.0000,  ..., -0.0000, -0.0000, 0.1439]), tensor([-0., -0., -0.,  ..., -0., -0., -0.]), tensor([69354.3672,    -0.0000,    -0.0000,  ...,    -0.0000,    -0.0000,\n           -0.0000])], 'acc': [91.93548387096774, 88.70967741935483, 80.64516129032258, 98.58934169278997, 99.52978056426332], 'n_params': [6234590, 5631262, 6576438, 5356576, 5834440]}\n\n=====> Generating 3th network  <=====\n\n\n=====>Generating sub_net<=====\n\n","output_type":"stream"},{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/mit-han-lab_once-for-all_master\n","output_type":"stream"},{"name":"stdout","text":"\n=====> Training started <=====\n\nStarting Training for:lego_bricks with model topology:[3, 3, 5, 5, 7, 5, 5, 5, 5, 5, 3, 3, 3, 3, 3, 7, 7, 3, 5, 5, 6, 4, 3, 4, 4, 4, 3, 6, 4, 3, 6, 4, 4, 4, 6, 6, 4, 4, 3, 6, 4, 2, 4, 3, 3]\n","output_type":"stream"},{"name":"stderr","text":"160it [00:22,  7.00it/s]\n20it [00:01, 17.55it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 1/5, Train Loss: 31.78787307 , Val Loss: 8.45999258, Val Accuracy: 91.22257053, Time: 24.29744339\n","output_type":"stream"},{"name":"stderr","text":"\n160it [00:22,  7.01it/s]\n20it [00:01, 16.42it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 2/5, Train Loss: 4.84281208 , Val Loss: 3.27899078, Val Accuracy: 95.61128527, Time: 24.28473592\n","output_type":"stream"},{"name":"stderr","text":"\n160it [00:22,  7.01it/s]\n20it [00:01, 17.16it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 3/5, Train Loss: 2.39741317 , Val Loss: 1.48009005, Val Accuracy: 98.90282132, Time: 24.27371645\n","output_type":"stream"},{"name":"stderr","text":"\n160it [00:22,  6.97it/s]\n20it [00:01, 16.54it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 4/5, Train Loss: 0.98825601 , Val Loss: 0.70580279, Val Accuracy: 99.37304075, Time: 24.44176388\n","output_type":"stream"},{"name":"stderr","text":"\n160it [00:22,  6.99it/s]\n20it [00:01, 17.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 5/5, Train Loss: 0.75378004 , Val Loss: 0.99943149, Val Accuracy: 98.90282132, Time: 24.35710669\n\n=====>Generating f_emb<=====\n\ntorch.Size([1536])\n{'dataset': ['corals', 'corals', 'corals', 'lego_bricks', 'lego_bricks', 'lego_bricks'], 'topol': [[3, 5, 5, 5, 7, 5, 5, 7, 3, 5, 7, 7, 7, 5, 7, 5, 3, 3, 7, 3, 4, 3, 6, 3, 6, 6, 4, 4, 6, 4, 3, 6, 6, 3, 4, 6, 3, 4, 6, 3, 3, 4, 2, 4, 4], [3, 7, 7, 7, 5, 7, 5, 3, 7, 5, 3, 3, 5, 5, 3, 7, 7, 5, 3, 5, 3, 4, 6, 3, 6, 4, 6, 4, 4, 3, 3, 3, 3, 6, 6, 3, 3, 4, 6, 4, 4, 3, 2, 2, 4], [3, 7, 5, 5, 3, 7, 7, 5, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 5, 7, 6, 6, 6, 3, 6, 3, 4, 4, 6, 6, 6, 4, 3, 6, 4, 6, 6, 4, 6, 4, 2, 3, 3, 3, 4], [7, 5, 3, 3, 5, 3, 5, 5, 5, 5, 3, 7, 7, 5, 7, 3, 3, 5, 3, 5, 3, 4, 6, 6, 6, 3, 6, 3, 6, 3, 6, 4, 4, 6, 6, 4, 6, 6, 6, 4, 2, 2, 2, 3, 2], [3, 5, 5, 7, 5, 5, 7, 3, 7, 5, 5, 5, 3, 5, 3, 7, 5, 7, 7, 3, 3, 6, 3, 3, 6, 3, 6, 6, 4, 4, 3, 4, 4, 3, 6, 6, 4, 3, 4, 3, 4, 3, 4, 4, 4], [3, 3, 5, 5, 7, 5, 5, 5, 5, 5, 3, 3, 3, 3, 3, 7, 7, 3, 5, 5, 6, 4, 3, 4, 4, 4, 3, 6, 4, 3, 6, 4, 4, 4, 6, 6, 4, 4, 3, 6, 4, 2, 4, 3, 3]], 'f_emb': [tensor([ 0.0133, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.3036]), tensor([-0.3080, -0.3462, -0.1965,  ..., -0.2554, -0.2233, -0.3557]), tensor([0.3410, -0.0000, -0.0000,  ..., -0.0000, -0.0000, 0.1439]), tensor([-0., -0., -0.,  ..., -0., -0., -0.]), tensor([69354.3672,    -0.0000,    -0.0000,  ...,    -0.0000,    -0.0000,\n           -0.0000]), tensor([-0., -0., -0.,  ..., -0., -0., -0.])], 'acc': [91.93548387096774, 88.70967741935483, 80.64516129032258, 98.58934169278997, 99.52978056426332, 98.90282131661442], 'n_params': [6234590, 5631262, 6576438, 5356576, 5834440, 4830848]}\n\n=====> GENERATING QUERIES <=====\n\nquery_shape_train: 32, each tensor:torch.Size([512])\nquery_shape_test: 32, each tensor:torch.Size([512])\nx_query:32, x_query-test :32\n\n=====>SAVING lego_bricks in m_train.pt <=====\n\n\n=====>SAVING {'dataset': ['corals', 'corals', 'corals', 'lego_bricks', 'lego_bricks', 'lego_bricks'], 'topol': [[3, 5, 5, 5, 7, 5, 5, 7, 3, 5, 7, 7, 7, 5, 7, 5, 3, 3, 7, 3, 4, 3, 6, 3, 6, 6, 4, 4, 6, 4, 3, 6, 6, 3, 4, 6, 3, 4, 6, 3, 3, 4, 2, 4, 4], [3, 7, 7, 7, 5, 7, 5, 3, 7, 5, 3, 3, 5, 5, 3, 7, 7, 5, 3, 5, 3, 4, 6, 3, 6, 4, 6, 4, 4, 3, 3, 3, 3, 6, 6, 3, 3, 4, 6, 4, 4, 3, 2, 2, 4], [3, 7, 5, 5, 3, 7, 7, 5, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 5, 7, 6, 6, 6, 3, 6, 3, 4, 4, 6, 6, 6, 4, 3, 6, 4, 6, 6, 4, 6, 4, 2, 3, 3, 3, 4], [7, 5, 3, 3, 5, 3, 5, 5, 5, 5, 3, 7, 7, 5, 7, 3, 3, 5, 3, 5, 3, 4, 6, 6, 6, 3, 6, 3, 6, 3, 6, 4, 4, 6, 6, 4, 6, 6, 6, 4, 2, 2, 2, 3, 2], [3, 5, 5, 7, 5, 5, 7, 3, 7, 5, 5, 5, 3, 5, 3, 7, 5, 7, 7, 3, 3, 6, 3, 3, 6, 3, 6, 6, 4, 4, 3, 4, 4, 3, 6, 6, 4, 3, 4, 3, 4, 3, 4, 4, 4], [3, 3, 5, 5, 7, 5, 5, 5, 5, 5, 3, 3, 3, 3, 3, 7, 7, 3, 5, 5, 6, 4, 3, 4, 4, 4, 3, 6, 4, 3, 6, 4, 4, 4, 6, 6, 4, 4, 3, 6, 4, 2, 4, 3, 3]], 'f_emb': [tensor([ 0.0133, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.3036]), tensor([-0.3080, -0.3462, -0.1965,  ..., -0.2554, -0.2233, -0.3557]), tensor([0.3410, -0.0000, -0.0000,  ..., -0.0000, -0.0000, 0.1439]), tensor([-0., -0., -0.,  ..., -0., -0., -0.]), tensor([69354.3672,    -0.0000,    -0.0000,  ...,    -0.0000,    -0.0000,\n           -0.0000]), tensor([-0., -0., -0.,  ..., -0., -0., -0.])], 'acc': [91.93548387096774, 88.70967741935483, 80.64516129032258, 98.58934169278997, 99.52978056426332, 98.90282131661442], 'n_params': [6234590, 5631262, 6576438, 5356576, 5834440, 4830848]} in model_zoo.pt <=====\n\n","output_type":"stream"}]},{"cell_type":"code","source":"model_zoo = {'dataset':['dataset1', 'dataset1', 'dataset2', 'dataset2', 'dataset3', 'dataset3'],\n             'topol':['model1', 'model2', 'model3', 'model4' , 'model5',  'model6'],\n             'acc':['acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6'],\n             'f_emb':['f_emb1', 'f_emb2', 'f_emb3', 'f_emb4', 'f_emb5', 'f_emb6'],\n             'n_params':['np1', 'np2', 'np3', 'np4', 'np5', 'np6']}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_zoo","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch \ntorch.save(model_zoo, 'zoo.pt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"zoo = torch.load('zoo.pt')\nprint(zoo)\nprint(type(zoo))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"zoo['dataset'].append('test')\nzoo['topol'].append('test')\nzoo['acc'].append('test')\nzoo['f_emb'].append('test')\nzoo['n_params'].append('test')\nprint(zoo)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nnoise = torch.randn([1, 3, 224, 224])\nprint(noise.shape)\ntorch.save(noise, 'noise.pt')","metadata":{"execution":{"iopub.status.busy":"2023-11-26T15:13:21.007937Z","iopub.execute_input":"2023-11-26T15:13:21.008335Z","iopub.status.idle":"2023-11-26T15:13:21.035120Z","shell.execute_reply.started":"2023-11-26T15:13:21.008299Z","shell.execute_reply":"2023-11-26T15:13:21.034252Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"torch.Size([1, 3, 224, 224])\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}